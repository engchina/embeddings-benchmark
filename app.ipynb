{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:29:56.363135Z",
     "start_time": "2024-11-16T16:29:56.360564Z"
    }
   },
   "source": "print(\"hello world!\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "ca41909259ce5a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:30:07.557623Z",
     "start_time": "2024-11-16T16:30:07.547962Z"
    }
   },
   "source": [
    "# read local .env file\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:30:08.682763Z",
     "start_time": "2024-11-16T16:30:07.975757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\"),  # This is the default and can be omitted\n",
    "    model=\"gpt-4\",\n",
    "    # model=\"BAAI/bge-m3\",\n",
    "    # model=\"multilingual-e5-large\",\n",
    "    # model=\"multilingual-e5-large-instruct\",\n",
    "    # dimensions=1536,\n",
    ")"
   ],
   "id": "d1fb33dd6299471a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:30:10.341675Z",
     "start_time": "2024-11-16T16:30:09.570057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text = \"The meaning of life is 42\"\n",
    "vector = embed.embed_query(input_text)\n",
    "print(vector[:3])\n",
    "print(len(vector))"
   ],
   "id": "ec68c74edf1110f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01183319091796875, 0.062469482421875, -0.0821533203125]\n",
      "1024\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:30:14.264362Z",
     "start_time": "2024-11-16T16:30:14.058864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def download_and_load_dataset():\n",
    "    # データセットのURL\n",
    "    dataset_url = \"https://raw.githubusercontent.com/yahoojapan/JGLUE/main/datasets/jsts-v1.1/valid-v1.1.json\"\n",
    "    \n",
    "    # ローカルファイルパスの設定\n",
    "    local_file = \"valid-v1.1.json\"\n",
    "    \n",
    "    # ファイルが存在しない場合はダウンロード\n",
    "    if not os.path.exists(local_file):\n",
    "        print(f\"Downloading dataset from {dataset_url}...\")\n",
    "        try:\n",
    "            with urlopen(dataset_url) as response:\n",
    "                content = response.read()\n",
    "            \n",
    "            # ダウンロードしたデータをローカルに保存\n",
    "            with open(local_file, 'wb') as f:\n",
    "                f.write(content)\n",
    "            print(f\"Dataset downloaded and saved to {local_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading file: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Loading dataset from local file: {local_file}\")\n",
    "    \n",
    "    # ローカルファイルからデータを読み込む\n",
    "    try:\n",
    "        with open(local_file, 'r', encoding='utf-8') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "        \n",
    "        # データフレームを作成\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# データセットを読み込む\n",
    "df = download_and_load_dataset()\n",
    "# データフレームの中身を確認\n",
    "if df is not None:\n",
    "    print(\"\\nDataset loaded successfully:\")\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to load dataset\")"
   ],
   "id": "211296a53817d1a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from local file: valid-v1.1.json\n",
      "\n",
      "Dataset loaded successfully:\n",
      "     sentence_pair_id               yjcaptions_id  \\\n",
      "0                   0  100312_421853-104611-31624   \n",
      "1                   1        100371-104675-104678   \n",
      "2                   2        100668-104946-104949   \n",
      "3                   3        100958-105177-105178   \n",
      "4                   4        101401-105530-105533   \n",
      "...               ...                         ...   \n",
      "1452             1452         98940-103167-103171   \n",
      "1453             1453         99222-103520-103521   \n",
      "1454             1454         99421-103771-103773   \n",
      "1455             1455         99453-103814-103815   \n",
      "1456             1456         99597-103941-103943   \n",
      "\n",
      "                                 sentence1                         sentence2  \\\n",
      "0              レンガの建物の前を、乳母車を押した女性が歩いています。                厩舎で馬と女性とが寄り添っています。   \n",
      "1                         山の上に顔の白い牛が2頭います。             曇り空の山肌で、牛が２匹草を食んでいます。   \n",
      "2                     バナナを持った人が道路を通行しています。            道の上をバナナを背負った男性が歩いています。   \n",
      "3                     スケートボーダーが手すりを滑っています。          階段の手すりでスケートボードをする男性がいます。   \n",
      "4               ダブルベッドの上で、女性が足を組み横たわっています。       ベッドの上に寝転んで、足を組んでいる人が映っています。   \n",
      "...                                    ...                               ...   \n",
      "1452                 男性が携帯電話を耳に当てて通話しています。  建物の前でシャツを着た男性が携帯電話を耳に当てて通話しています。   \n",
      "1453  カウンターに、バナナ、サニーレタス、マッシュルームなどが置かれています。      キッチンの机の上に野菜と果物がたくさん並べられています。   \n",
      "1454                    棚に白い電子レンジが置いてあります。              レンジと調理家電が棚の上に乗っています。   \n",
      "1455            部屋の中に置かれた自転車のサドルに猫が座っています。          白い猫のしっぽが一匹自転車の荷台に乗っています。   \n",
      "1456              湖畔の側の草むらで、３頭の馬が草を食べています。           湖の側の草むらで、３頭の馬が草を食べています。   \n",
      "\n",
      "      label  \n",
      "0       0.0  \n",
      "1       2.4  \n",
      "2       3.6  \n",
      "3       4.0  \n",
      "4       3.0  \n",
      "...     ...  \n",
      "1452    3.6  \n",
      "1453    3.8  \n",
      "1454    2.6  \n",
      "1455    2.8  \n",
      "1456    4.2  \n",
      "\n",
      "[1457 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:30:15.552837Z",
     "start_time": "2024-11-16T16:30:14.670629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import concurrent.futures\n",
    "\n",
    "# データセットからsentence1とsentence2を抜き出して連結\n",
    "set_sentence = set(df[\"sentence1\"]).union(set(df[\"sentence2\"]))\n",
    "print(len(set_sentence))"
   ],
   "id": "f5610559bc2f94bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2808\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:30:23.686004Z",
     "start_time": "2024-11-16T16:30:15.554002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# データセットをembedding(concurrent.futuresで並列処理)\n",
    "dict_sentence = {}\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # set_sentenceの各要素に対して、embed_query関数を並行に適用\n",
    "    future_to_sentence = {\n",
    "        executor.submit(embed.embed_query, sentence): sentence\n",
    "        for sentence in set_sentence\n",
    "    }\n",
    "    for future in concurrent.futures.as_completed(future_to_sentence):\n",
    "        sentence = future_to_sentence[future]\n",
    "        try:\n",
    "            dict_sentence[sentence] = future.result()\n",
    "        except Exception as exc:\n",
    "            print(\"%r generated an exception: %s\" % (sentence, exc))\n",
    "\n",
    "# ベクトル化したデータセット(ディクショナリ)を確認\n",
    "print(len(dict_sentence))"
   ],
   "id": "319754834d6ad405",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2808\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:30:23.906496Z",
     "start_time": "2024-11-16T16:30:23.687142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# コサイン類似度を使うためcosine_similarityをimport\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "# コサイン類似度を算出し配列に入力\n",
    "similarities = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    embed_sentence1 = dict_sentence[row[\"sentence1\"]]\n",
    "    embed_sentence2 = dict_sentence[row[\"sentence2\"]]\n",
    "    similarity = cosine_similarity(\n",
    "        torch.tensor(embed_sentence1).unsqueeze(0), torch.tensor(embed_sentence2).unsqueeze(0)\n",
    "    )\n",
    "    similarities.append(similarity.item())"
   ],
   "id": "97c2488a76bfa86a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1457it [00:00, 7121.32it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:30:24.315955Z",
     "start_time": "2024-11-16T16:30:23.907283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# ピアソン相関係数の算出\n",
    "pearson_corr, _ = pearsonr(similarities, df[\"label\"])\n",
    "print(f'Pearson correlation: {pearson_corr}')\n",
    "\n",
    "# スピアマン相関係数の算出\n",
    "spearman_corr, _ = spearmanr(similarities, df[\"label\"])\n",
    "print(f'Spearman correlation: {spearman_corr}')"
   ],
   "id": "a0a2aa890c25836f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.20309295991098175\n",
      "Spearman correlation: 0.25997977887797685\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## BAAI/bge-m3\n",
    "- Pearson correlation: 0.20309295991098175\n",
    "- Spearman correlation: 0.25997977887797685\n",
    "\n",
    "- Pearson correlation: 0.8466529839655326\n",
    "- Spearman correlation: 0.8022972686208227\n",
    "\n",
    "## BAAI/bge-multilingual-gemma2\n",
    "- Pearson correlation: 0.32889489844536185\n",
    "- Spearman correlation: 0.3410501003671425\n",
    "\n",
    "## Alibaba-NLP/gte-Qwen2-7B-instruct\n",
    "- Pearson correlation: 0.5205752281045795\n",
    "- Spearman correlation: 0.5510142337149282\n",
    "\n",
    "## intfloat/multilingual-e5-large-instruct\n",
    "- Pearson correlation: 0.5228528008921871\n",
    "- Spearman correlation: 0.540391660332006\n",
    "\n",
    "- Pearson correlation: 0.8634430697527975\n",
    "- Spearman correlation: 0.8187526901653888\n",
    "\n",
    "## intfloat/multilingual-e5-large\n",
    "- Pearson correlation: 0.5447470095324037\n",
    "- Spearman correlation: 0.5628063344366232\n",
    "\n",
    "- Pearson correlation: 0.850360223135657\n",
    "- Spearman correlation: 0.8098701611897999\n",
    "\n",
    "# Cohere embed-multilingual-v3.0\n",
    "- Pearson correlation: 0.8689620805910541\n",
    "- Spearman correlation: 0.8218902671771843"
   ],
   "id": "9cd0be93e64d377f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef50b03ed4a85772"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
